# -*- coding: utf-8 -*-
"""ML7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v-Ml85fRxpYVRgTeC6ZNXegHrOoFM9SM
"""

def clean_text(text):
  import re
  import nltk
  import ssl
  from nltk.corpus import stopwords
  # try:
  #   _create_unverified_https_context = ssl._create_unverified_context
  # except AttributeError:
  #   pass
  # else:
  #   ssl._create_default_https_context = _create_unverified_https_context
  nltk.download('stopwords')
  REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
  BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
  STOPWORDS = set(stopwords.words('english'))
  text = text.lower() # lowercase text
  text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
  text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
  text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text
  return text

# Commented out IPython magic to ensure Python compatibility.
def ml(stry):
  import pandas as pd
  import numpy as np
  from numpy import random
  import gensim
  import nltk
  from sklearn.model_selection import train_test_split
  from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
  from sklearn.metrics import accuracy_score, confusion_matrix
  import matplotlib.pyplot as plt
  from nltk.corpus import stopwords
  import re
  from bs4 import BeautifulSoup
#   %matplotlib inline
  import io 
  # from google.colab import files
  from io import StringIO
  from sklearn.feature_extraction.text import TfidfVectorizer
  from sklearn.model_selection import train_test_split
  from sklearn.feature_extraction.text import CountVectorizer
  from sklearn.feature_extraction.text import TfidfTransformer
  from sklearn.naive_bayes import MultinomialNB
  from sklearn.feature_selection import chi2
  # uploaded=files.upload()
  # df = pd.read_csv(io.BytesIO(uploaded['ad.csv']))
  df = pd.read_csv('ad.csv')
  #print(df)
  df.drop(["Advertiser","Product_or_spot"],axis=1,inplace=True)
  df.head()
  #print(df['Category'].value_counts())
  df['Ad_copy'].apply(lambda x: len(x.split(' '))).sum()
  #my_tags = df["Category"].tolist()
  #plt.figure(figsize=(10,4))
  #df.Category.value_counts().plot(kind='bar');
  df['Category'] = df['Category'].replace(['HeaLth Care'],'Health Care')
  #print_plot(10)
  df['category_id'] = df['Category'].factorize()[0]
  category_id_df = df[['Category', 'category_id']].drop_duplicates().sort_values('category_id')
  category_to_id = dict(category_id_df.values)
  id_to_category = dict(category_id_df[['category_id', 'Category']].values)
  df.head()
  
  df['Ad_copy'] = df['Ad_copy'].apply(clean_text)

  #print_plot(10)
  
  tfidf = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', ngram_range=(1, 2), stop_words='english')
  features = tfidf.fit_transform(df.Ad_copy).toarray()
  labels = df.category_id
  features.shape
  N = 2
  for Category, category_id in sorted(category_to_id.items()):
    features_chi2 = chi2(features, labels == category_id)
    indices = np.argsort(features_chi2[0])
    feature_names = np.array(tfidf.get_feature_names_out())[indices]
    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]
    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]
  
  X_train, X_test, y_train, y_test = train_test_split(df['Ad_copy'], df['Category'], random_state = 0)
  count_vect = CountVectorizer()
  X_train_counts = count_vect.fit_transform(X_train)
  tfidf_transformer = TfidfTransformer()
  X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
  clf = MultinomialNB().fit(X_train_tfidf, y_train)
  #print(clf.predict(count_vect.transform([stry])))
  from sklearn.linear_model import LogisticRegression
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.svm import LinearSVC
  from sklearn.model_selection import cross_val_score
  models = [RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),LinearSVC(),MultinomialNB(),LogisticRegression(random_state=0),]
  CV = 5
  model = LinearSVC()
  X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  from sklearn.metrics import confusion_matrix
  conf_mat = confusion_matrix(y_test, y_pred)
  #fig, ax = plt.subplots(figsize=(10,10))
  model.fit(features, labels)   
  N = 2
  for Category, category_id in sorted(category_to_id.items()):
    indices = np.argsort(model.coef_[category_id])
    feature_names = np.array(tfidf.get_feature_names_out())[indices]
    unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]
    bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]
  x=clf.predict(count_vect.transform([stry]))
  return x
